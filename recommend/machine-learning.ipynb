{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考にしたページ\n",
    "\n",
    "http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/\n",
    "\n",
    "http://qiita.com/ysekky/items/c81ff24da0390a74fc6c\n",
    "\n",
    "https://qiita.com/takechanman/items/6d1f65f94f7aaa016377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方策\n",
    "* CV以外の情報からCVした商品を予測する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# numpyのループを早くしてくれるやつ\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小さいデータのサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.NANの部分は未知\n",
    "score = np.array([\n",
    "        [5, 3, 0, 1],\n",
    "        [4, 0, 0, 1],\n",
    "        [1, 1, 0, 5],\n",
    "        [1, 0, 0, 4],\n",
    "        [0, 1, 5, 4],\n",
    "        ]\n",
    "    )\n",
    "buy = np.array([\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 0, 0],\n",
    "        [0, 1, 1, 0],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(score).values\n",
    "y = pd.DataFrame(buy).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 入出力の大きさ\n",
    "dimension = len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create regression model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def reg_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=dimension, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(dimension))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s - loss: 0.3351\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s - loss: 0.0934\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s - loss: 0.0599\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s - loss: 0.0357\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s - loss: 0.0300\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s - loss: 0.0274\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s - loss: 0.0230\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s - loss: 0.0179\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s - loss: 0.0162\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s - loss: 0.0162\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s - loss: 0.0143\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s - loss: 0.0105\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s - loss: 0.0079\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s - loss: 0.0078\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s - loss: 0.0085\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s - loss: 0.0073\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s - loss: 0.0049\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s - loss: 0.0036\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s - loss: 0.0037\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s - loss: 0.0038\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s - loss: 0.0029\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s - loss: 0.0020\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s - loss: 0.0016\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s - loss: 0.0016\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s - loss: 0.0015\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s - loss: 0.0012\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s - loss: 7.8952e-04\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s - loss: 5.1650e-04\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s - loss: 5.3841e-04\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s - loss: 6.2256e-04\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s - loss: 5.3012e-04\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s - loss: 2.8889e-04\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s - loss: 2.1922e-04\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s - loss: 3.4011e-04\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s - loss: 3.3318e-04\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s - loss: 2.0265e-04\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s - loss: 1.8094e-04\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s - loss: 2.7371e-04\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s - loss: 2.7289e-04\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s - loss: 1.8839e-04\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s - loss: 1.7958e-04\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s - loss: 2.0581e-04\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s - loss: 1.6022e-04\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s - loss: 1.1259e-04\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s - loss: 1.0711e-04\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s - loss: 1.2455e-04\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s - loss: 8.7222e-05\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s - loss: 4.9950e-05\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s - loss: 5.6463e-05\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s - loss: 6.4635e-05\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s - loss: 4.9888e-05\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s - loss: 3.9262e-05\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s - loss: 4.3579e-05\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s - loss: 4.0240e-05\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s - loss: 3.5253e-05\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s - loss: 3.6922e-05\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s - loss: 3.3529e-05\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s - loss: 2.8035e-05\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s - loss: 2.9850e-05\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s - loss: 2.9513e-05\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s - loss: 1.6559e-05\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s - loss: 1.0331e-05\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s - loss: 1.6458e-05\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s - loss: 1.5414e-05\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s - loss: 8.0432e-06\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s - loss: 7.8607e-06\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s - loss: 1.2656e-05\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s - loss: 1.1597e-05\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s - loss: 8.3299e-06\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s - loss: 6.3604e-06\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s - loss: 8.7720e-06\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s - loss: 9.1649e-06\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s - loss: 6.5368e-06\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s - loss: 3.9194e-06\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s - loss: 4.7955e-06\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s - loss: 5.6187e-06\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s - loss: 2.4091e-06\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s - loss: 1.1977e-06\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s - loss: 3.6661e-06\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s - loss: 3.6700e-06\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s - loss: 1.6742e-06\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s - loss: 1.9765e-06\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s - loss: 2.9003e-06\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s - loss: 2.4340e-06\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s - loss: 1.5629e-06\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s - loss: 1.6661e-06\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s - loss: 1.6542e-06\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s - loss: 1.2444e-06\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s - loss: 7.2059e-07\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s - loss: 7.9236e-07\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s - loss: 1.0061e-06\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s - loss: 8.3710e-07\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s - loss: 6.1091e-07\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s - loss: 6.7775e-07\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s - loss: 6.9939e-07\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s - loss: 5.6642e-07\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s - loss: 4.8602e-07\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s - loss: 5.3189e-07\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s - loss: 4.9185e-07\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s - loss: 3.3081e-07\n",
      "5/5 [==============================] - 0s\n",
      "KERAS REG RMSE : 0.00\n"
     ]
    }
   ],
   "source": [
    "# use data split and fit to run the model\n",
    "estimator = KerasRegressor(build_fn=reg_model, epochs=100, batch_size=10, verbose=1)\n",
    "estimator.fit(X, y)\n",
    "y_pred = estimator.predict(X)\n",
    "\n",
    "# show its root mean square error\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"KERAS REG RMSE : %.2f\" % (mse ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3\n",
       "0  1  0  0  1\n",
       "1  1  0  0  0\n",
       "2  0  1  0  0\n",
       "3  0  0  0  0\n",
       "4  0  1  1  0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3\n",
       "0  5  3  0  1\n",
       "1  4  0  0  1\n",
       "2  1  1  0  5\n",
       "3  1  0  0  4\n",
       "4  0  1  5  4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.999857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>-0.000498</td>\n",
       "      <td>-0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000572</td>\n",
       "      <td>1.000596</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.001289</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.999383  0.000046 -0.000629  0.999857\n",
       "1  0.999945  0.000205 -0.000498 -0.000180\n",
       "2  0.000572  1.000596 -0.000150  0.000460\n",
       "3 -0.000222 -0.000363  0.000286  0.001324\n",
       "4  0.000141  0.999596  1.001289  0.000092"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 値が大きい順にそれっぽい予測ができていそうな気がする。\n",
    "# できていなさそうな気もする。\n",
    "pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = './train/train_A.tsv'\n",
    "sep = '\\t'\n",
    "target_df = pd.read_csv(file_path, sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# コンバージョンは広告経由のみ評価対象とか書いてあってめんどくさい\n",
    "# ad=1が広告経由のコンバージョン、ad=-1はコンバージョン以外のイベント\n",
    "score_df = target_df[target_df[u'ad'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ピボットテーブル\n",
    "# 値の無いところは0で埋める\n",
    "# カートは評価に影響しない？ので0のままsumする\n",
    "score  = pd.pivot_table(score_df, values=u'event_type', index=[u'user_id'], columns=[u'product_id'], aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 購買した商品\n",
    "buy_df = target_df[target_df[u'ad'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scoreをbuyにコピーして、0埋め。購買した商品の部分にフラグを立てる。\n",
    "buy = score\n",
    "buy[:] = 0\n",
    "for b in buy_df.iterrows():\n",
    "    buy.loc[b[1].user_id,b[1].product_id] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = score.as_matrix()\n",
    "y = buy.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 入出力の大きさ\n",
    "dimension = len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13864"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13864"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# callback\n",
    "filename = 'machine'\n",
    "log_filepath = './log_files/{}'.format(filename)\n",
    "\n",
    "import os\n",
    "\n",
    "def make_my_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "tensor_board_path = os.path.join(log_filepath,'tensor_board')\n",
    "make_my_dir(tensor_board_path)\n",
    "tb_cb = TensorBoard(log_dir=tensor_board_path, histogram_freq=1)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "weights_path = os.path.join(log_filepath,'weights')\n",
    "make_my_dir(weights_path)\n",
    "weights_file_name = os.path.join(weights_path,'weights.{epoch:02d}-{loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = weights_file_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create regression model\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(seed=7)\n",
    "\n",
    "def reg_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=dimension, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(dimension))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58650/58658 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-de90b67f9611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use data split and fit to run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_cb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcp_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/wrappers/scikit_learn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# use data split and fit to run the model\n",
    "estimator = KerasRegressor(build_fn=reg_model, epochs=100, batch_size=dimension/100, verbose=1, callbacks=[tb_cb,cp_cb])\n",
    "estimator.fit(X, y)\n",
    "y_pred = estimator.predict(X)\n",
    "\n",
    "# show its root mean square error\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"KERAS REG RMSE : %.2f\" % (mse ** 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レコメンド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 購買ログにフラグを立てる\n",
    "buy_log_df = target_df\n",
    "buy_log_df[u'buy_flg'] = target_df[u'event_type'].apply(lambda x: 1 if x == 3 else 0)\n",
    "buy_log_pivot_df  = pd.pivot_table(buy_log_df, values=u'buy_flg', index=[u'user_id'], columns=[u'product_id'], aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 嗜好情報をdfに\n",
    "# 一部バージョン\n",
    "ratio_df = pd.DataFrame(nR, index=view_log_pivot_df.index[:10], columns=view_log_pivot_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# レコメンド取得用関数\n",
    "def get_recommend_items(user_id, ratio_df, buy_log_df, recommend_item_num=22):\n",
    "    # product_idを対象ユーザのスコア順にソート\n",
    "    products = ratio_df.loc[user_id].sort_values(ascending=False)\n",
    "    # 購買履歴のある商品を省く\n",
    "    buy_log = buy_log_df.loc[user_id]\n",
    "    # レコメンド対象の商品リスト\n",
    "    recommend_items = []\n",
    "    for index in products.index:\n",
    "        # 購買履歴のある商品は無視\n",
    "        if buy_log[index] != 0:\n",
    "            continue\n",
    "        # 提出時の命名規則でappend\n",
    "        recommend_items.append([user_id, index, len(recommend_items)])\n",
    "        # 引数で指定した個数または規程個数(22個)を超えたら終了\n",
    "        if len(recommend_items) >= recommend_item_num or len(recommend_items) >= 22:\n",
    "            break\n",
    "    return recommend_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_recommend_items('0000000_A', ratio_df, buy_log_pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learnを使ってNMFを計算する場合\n",
    "通常のScikit-learnのNMFは欠損値を扱えないので、下記フォークのnmf_missingブランチの内容をインストールする。\n",
    "`git checkout origin/nmf_missing`\n",
    "https://github.com/TomDLT/scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "('k:', 2)\n",
      "Pは\n",
      "[[ 0.25533737  2.31920431]\n",
      " [ 0.2749493   1.8405892 ]\n",
      " [ 1.74751251  0.10992921]\n",
      " [ 1.39405084  0.18346339]\n",
      " [ 1.39101969  0.25440826]]\n",
      "Q^Tは\n",
      "[[ 0.43984129  0.49350833  3.05253861  2.85396988]\n",
      " [ 2.10749104  1.23916027  2.96318486  0.11698132]]\n",
      "P×Q^Tは\n",
      "[[ 5.00001021  2.99987694  7.65165828  1.00002874]\n",
      " [ 3.99995931  2.41647477  6.29329943  1.00001158]\n",
      " [ 1.00030298  0.99863188  5.66008999  5.00020773]\n",
      " [ 0.99980858  0.91531625  4.79902998  4.00004091]\n",
      " [ 1.14799101  1.0017324   5.          3.9996893 ]]\n",
      "R-P×Q^Tは\n",
      "0.00227169772504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# R = target_log_pivot_df.as_matrix()[:10]\n",
    "R = np.array([\n",
    "        [5, 3, np.NAN, 1],\n",
    "        [4, np.NAN, np.NAN, 1],\n",
    "        [1, 1, np.NAN, 5],\n",
    "        [1, np.NAN, np.NAN, 4],\n",
    "        [np.NAN, 1, 5, 4],\n",
    "        ]\n",
    "    )\n",
    "k = 2\n",
    "model = NMF(n_components=k, init='random', random_state=0, solver='mu', max_iter=1000)\n",
    "P = model.fit_transform(R)\n",
    "Q = model.components_\n",
    "print(\"****************************\")\n",
    "print(\"k:\",k)\n",
    "print(\"Pは\")\n",
    "print(P)\n",
    "print(\"Q^Tは\")\n",
    "print(Q)\n",
    "print(\"P×Q^Tは\")\n",
    "print(np.dot(P,Q))\n",
    "print(\"R-P×Q^Tは\")\n",
    "print(model.reconstruction_err_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発展？\n",
    "http://tech-blog.fancs.com/entry/factorization-machines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
