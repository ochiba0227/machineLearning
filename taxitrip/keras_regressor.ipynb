{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New York City Taxi Trip Duration\n",
    "https://www.kaggle.com/c/nyc-taxi-trip-duration/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 説明変数と目的変数に分ける\n",
    "X = train_data.iloc[:,:-1]\n",
    "Y = train_data['trip_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vendor_idをワンホット化\n",
    "import numpy as np\n",
    "\n",
    "def toOneHot(target_data):\n",
    "    n_labels = len(np.unique(target_data))\n",
    "    return np.eye(n_labels+1)[target_data]\n",
    "\n",
    "def toOneHotDataFrame(target_data, label_prefix=''):\n",
    "    oneHotData = toOneHot(target_data)\n",
    "    oneHotDataFrame = pd.DataFrame(oneHotData)\n",
    "    # カラム名を書き換え\n",
    "    if(label_prefix!=''):\n",
    "        oneHotDataFrame.columns = map(lambda x: '{}_{}'.format(label_prefix, x), oneHotDataFrame.columns)\n",
    "    return oneHotDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_prefix = 'vendor_id'\n",
    "# print(toOneHotDataFrame(X[label_prefix], label_prefix))\n",
    "# 使用する説明変数を選択\n",
    "X_target = X.loc[:,['passenger_count','pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']]\n",
    "oneHotVendorIdDataFrame = toOneHotDataFrame(X[label_prefix], label_prefix)\n",
    "# ワンホットしたやつを結合している\n",
    "X_selected = pd.concat([X_target, oneHotVendorIdDataFrame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 学習用データと検証用データに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 予測誤差の計算用\n",
    "# 　https://www.kaggle.com/marknagelberg/rmsle-function\n",
    "import math\n",
    "\n",
    "#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# callback\n",
    "filename = 'keras_regressor'\n",
    "log_filepath = './log_files/{}'.format(filename)\n",
    "\n",
    "import os\n",
    "\n",
    "def make_my_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
    "import numpy as np\n",
    "# TensorBoard\n",
    "tensor_board_path = os.path.join(log_filepath,'tensor_board')\n",
    "make_my_dir(tensor_board_path)\n",
    "tb_cb = TensorBoard(log_dir=tensor_board_path, histogram_freq=1)\n",
    "\n",
    "# ModelCheckpoint\n",
    "weights_path = os.path.join(log_filepath,'weights')\n",
    "make_my_dir(weights_path)\n",
    "weights_file_name = os.path.join(weights_path,'weights.{epoch:02d}-{loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = weights_file_name, monitor='loss', verbose=0, save_best_only=True, mode='auto')\n",
    "\n",
    "# LearningRateScheduler\n",
    "def make_lr_cb(nb_epoch = 200):\n",
    "    learning_rates = np.logspace(-2,-4, nb_epoch)\n",
    "    lr_cb = LearningRateScheduler(lambda epoch: float(learning_rates[epoch]))\n",
    "    return lr_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1166915/1166915 [==============================] - 227s - loss: 35.1473   \n",
      "Epoch 2/100\n",
      " 170993/1166915 [===>..........................] - ETA: 195s - loss: 35.0311"
     ]
    }
   ],
   "source": [
    "# hyperoptのドキュメント\n",
    "# https://github.com/hyperopt/hyperopt/wiki/FMin\n",
    "from hyperopt import fmin, tpe, hp, rand\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# 走査対象のパラメータ\n",
    "parameters = {\n",
    "            'units1': hp.choice('units1', np.arange(64, 1024+1, dtype=int)),\n",
    "            'units2': hp.choice('units2', np.arange(64, 1024+1, dtype=int)),\n",
    "\n",
    "            'dropout1': hp.uniform('dropout1', .25,.75),\n",
    "            'dropout2': hp.uniform('dropout2',  .25,.75),\n",
    "\n",
    "            'batch_size' : hp.choice('batch_size', np.arange(8, 128+1, dtype=int)),\n",
    "\n",
    "            'nb_epochs' :  100,\n",
    "            'optimizer': hp.choice('optimizer',['adadelta','adam','rmsprop','sgd']),\n",
    "            'activation': 'relu'\n",
    "        }\n",
    "\n",
    "def regression_model(params):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['units1'], input_dim=8, kernel_initializer='normal', activation=params['activation']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(params['units2'], kernel_initializer='normal', activation=params['activation']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_logarithmic_error', optimizer=params['optimizer'])\n",
    "    return model\n",
    "\n",
    "def learningFunction(params):\n",
    "    # 学習率変更用のコールバック\n",
    "    lr_cb = make_lr_cb(params['nb_epochs'])\n",
    "    \n",
    "    # 学習\n",
    "    estimator = regression_model(params)\n",
    "    estimator.fit(X_train.as_matrix(), y_train.as_matrix(), epochs=params['nb_epochs'], batch_size=params['batch_size'], verbose=1, callbacks=[tb_cb, cp_cb, lr_cb])\n",
    "\n",
    "    # 予測\n",
    "    X_test_reindexed = X_test.reset_index(drop=True)\n",
    "    y_test_reindexed = y_test.reset_index(drop=True)\n",
    "    y_pred = xgbr.predict(X_test_reindexed)\n",
    "\n",
    "    # マイナスになっちゃう奴はひとまず値を反転\n",
    "    for i, yp in enumerate(y_pred):\n",
    "        if yp < 0:\n",
    "            y_pred[i] = abs(yp)\n",
    "\n",
    "    # 予測誤差の計算\n",
    "    return rmsle(y_test_reindexed, y_pred)\n",
    "\n",
    "# パラメータ良い奴自動選択\n",
    "best = fmin(learningFunction,parameters,algo=tpe.suggest,max_evals=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ベストなモデルに全データぶっ込んで学習\n",
    "xgbr = XGBRegressor(**best)\n",
    "xgbr.fit(X_selected.as_matrix(), Y.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テストデータの読み込み\n",
    "test_data = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用する説明変数を選択\n",
    "test_data_target = test_data.loc[:,['passenger_count','pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']]\n",
    "oneHotVendorIdDataFrame_test_data = toOneHotDataFrame(test_data[label_prefix], label_prefix)\n",
    "# ワンホットしたやつを結合している\n",
    "test_data_selected = pd.concat([test_data_target, oneHotVendorIdDataFrame_test_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 予測\n",
    "result = estimator.predict(test_data_selected.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# マイナスになっちゃう奴はひとまず値を反転\n",
    "for i, yp in enumerate(result):\n",
    "    if yp < 0:\n",
    "        result[i] = abs(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 提出できる形式に変換\n",
    "id_list = test_data['id']\n",
    "result_dataFrame = pd.DataFrame([id_list, result], index = ['id', 'trip_duration']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ファイル書き出し\n",
    "from datetime import datetime as dt\n",
    "\n",
    "tdatetime = dt.now()\n",
    "tstr = tdatetime.strftime('%Y%m%d_%H%M')\n",
    "result_dataFrame.to_csv('{}_submission_{}.csv'.format(filename,tstr), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
